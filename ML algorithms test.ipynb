{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grade: /100\n",
    "\n",
    "## Instructions\n",
    "\n",
    "\n",
    "\n",
    "* Once the notebook is complete, restart your kernel and rerun your cells\n",
    "\n",
    "* Submit this notebook to owl by the deadline\n",
    "\n",
    "* You may use any python library functions you wish to complete the Lab assignment.\n",
    "\n",
    "\n",
    "\n",
    "This notebook contains the questions for Assignment 1. Please note, a random seed has been set to ensure the reproducability of the results -- *DO NOT* change this random seed. **If you call additional functions that are based on random number generators, you will need to define their seed as well**. Make sure to complete this assignment individually and appropriately reference all external code and documentation used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "In this Assignmnet you will use 2 separate datasets. Datasets are entitled according to the exam Questions (Dataset1 to be used in Question1, and Dataset2 to be used in Question2).  \n",
    "\n",
    "You need to download datasets from OWL in the `Assignments / Assignment1`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "Feel free to add any libraries to the Preliminaries. However, be mindful of every question's restrictions as some may exclude use of some functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform the necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.metrics import recall_score, make_scorer, mean_squared_error, confusion_matrix, roc_curve, auc, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Model Selection (70 pts)\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this question you need to download and use Dataset1. \n",
    "\n",
    "Dataset1 lists the soccer players participated in the 2022 FIFA World Cup. Our ultimate goal is to find the best ML model among three candidates that can best predict a player's monetary \"Value\". The dataset has the following attributes:\n",
    "- Age: Player age in years\n",
    "- Nationality: Players nationality\n",
    "- Overall: Player overall performance score (higher better)\n",
    "- Potential: Player potential score (higher better)\n",
    "- Club: Player home soccer club\n",
    "- Value: Player value *i.e*, the amount of money a club should pay in order to purchase the player (higher better)\n",
    "- Wage: Player stipend (higher better)\n",
    "- Preferred Foot: Player preferred foot to play\n",
    "- International Reputation: Player international fame (higher better)\n",
    "- Week Foot: Performance score of player weak foot (higher better)\n",
    "- Skill Moves: Player move skill score (higher better)\n",
    "- Body Type: Player body type\n",
    "- Position: Position player holds on the pitch\n",
    "- Height: Player height in CM\n",
    "- Weight: Player weight in kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1 - Data loading  (8 pts)\n",
    "\n",
    "- Load `Dataset1.csv` as a pandas dataframe, and display its first 5 rows. \n",
    "- Show the statistical summary of the data. \n",
    "- How many missing values does dataset contain? \n",
    "- Dummy code catecorical variables (drop the first). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2 - Feature extraction  (6 pts)\n",
    "\n",
    "- Use `sns.jointplot` to plot the joint distribution between Weight and Height. \n",
    "- The BMI is defined as the body mass divided by the square of the body height, and is expressed in units of kg/mÂ². With this knowledge, see if you can do some meaningful feature extraction and then drop Weight and Height. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3 - Transformations  (9 pts)\n",
    "\n",
    "Use `sns.jointplot` to investigate the following relationships and apply Logarithm transformation and replace the feature with its transformation **where needed** (Drop the variables that has been transformed and keep the logarithm transformation of that variable instead):\n",
    "\n",
    "Note: plot joint distributions **before** and **after** trasformation (if it's needed) to make sure the transformation fixes the problem. \n",
    "- Value vs. Wage\n",
    "- Value vs. Overall\n",
    "- Value vs. Potential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.4 - Data split  (5 pts)\n",
    "\n",
    "- Split data to put aside 20% for testing purpose (with `random_state=1220`). \n",
    "  \n",
    "  *Note: keep the Value (or LogValue if you transformed it in Question 1.3) as the target variable, and use the remaining variables as features.* \n",
    "  \n",
    "\n",
    "- Also define an RMSE scorer function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.5 - Linear Regression  (8 pts)\n",
    "\n",
    "-   Implement shuffled 5-split Kfold cross-validation on the sklearn's linear regression (with default arguments) and RMSE scorer function above and report the mean of cross validation score.\n",
    "-   Fit the model to the training set. \n",
    "-   Report prediction RMSE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.6 - Ridge Regression  (8 pts)\n",
    "\n",
    "Bundle the StandardScaler with the sklearn's ridge regression (with default arguments except alpha = 1e-10) into a Pipeline, and:\n",
    "\n",
    "- Implement shuffled 5-split Kfold cross-validation on the pipeline and report the mean of cross-validated RMSE score. \n",
    "- Fit the model to the training set. \n",
    "- Report prediction RMSE score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.7 - Random Forest  (10 pts)\n",
    "\n",
    "-   Implement shuffled 5-split Kfold cross-validation on the sklearn's random forest regressor (using \"RandomForestRegressor\" from sklearn.ensemble library with default arguments except `n_jobs=-1`, and `random_state=1220`), and report the mean of cross-validated RMSE score.\n",
    "-   Fit the model to the training set \n",
    "-   Report prediction RMSE score\n",
    "-   Use `barplot` to generate the feature importance diagram from this model (limit the plot to the top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.8 - Random Forest  and Gridsearch  (14 pts)\n",
    "\n",
    "- Use the cross-validated grid search tool (5-fold) to find the best possible values for `n_estimators` for your forest. Here are the degrees of freedom for `n_estimators` try `[50, 100, 150]`. Use your RMSE scorer function and put `n_jobs=-1`, `refit = False`, then report the best values found.\n",
    "\n",
    "- Take the random forest regressor again but this time use the best values found in the previous step, and again:\n",
    "     -   Implement shuffled 5-split Kfold cross-validation on the sklearn's random forest regressor with the best `n_estimators` you found, `n_jobs=-1`, and `random_state=1220`), and report the mean of cross-validated RMSE score.\n",
    "     -   Fit the model to the training set. \n",
    "     -   Report prediction RMSE score.\n",
    "     -   Use `barplot` to generate the feature importance diagram from this model (limit the plot to the top 5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.9 - Comparison  (2 pts)\n",
    "\n",
    "**Written question:** From what you have seen in all your results, if you are asked to choose one final model to go into production, which one would you select? (Take computational complexity into account too)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your written answer here **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Clustering (30 pts)\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this question you need to download and use Dataset2. \n",
    "\n",
    "This dataset is a modified dataset from UCI Machine Learning Datasets. The data contains selling feature on a social media platform. Each record has information about the time the information is posted and engagements in the data (such as emotion). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1 Data load and normalization (12 pts)\n",
    "\n",
    "- Load the Dataset. \n",
    "\n",
    "- How many observations and attributes do you have in Data set?\n",
    "\n",
    "- Check for missing values and drop the columns that contain missing values, and ID column.\n",
    "\n",
    "- Create a label encoder using \"LabelEncoder\" from scikit learn and convert categorical label (`data_type`) into integers. \n",
    "\n",
    "- Then train a ```MinMaxScaler``` method over your full dataset. (**Note**: save a sample of `data_type` column before normalization for further use as the label later in Question 2.3). \n",
    "\n",
    "- **Written question:** Explain why it is a good idea to normalize the data for a K-Means clustering process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your written answer here **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2 K-Means Clustering - Silhouette (10 pts)\n",
    "\n",
    "- Use K-means to cluster data. Run a silhouette analysis over the data to answer these question. Create a silhouette plot for 2, 3, and 4 clusters and calculate the corresponding silhouette scores. Use a random seed of 20211231 for your cluster functions. \n",
    "\n",
    "- **Written question:** How many clusters would you say the silhouette analysis show are in the data? Why?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your written answer here **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3 K-Means Clustering - Elbow (8 pts)\n",
    "\n",
    "- Use elbow method to find optimal number of clusters for up to 10 clusters. \n",
    "- Compare the models accuracy for the best three number of clusters (Hint: use \"kmeans.fit\").\n",
    "- **Written question:** Explain your final decision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your written answer here **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
